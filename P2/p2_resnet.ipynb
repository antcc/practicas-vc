{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p2_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEvpRBWYYa21",
        "colab_type": "text"
      },
      "source": [
        "Necesitamos que la carpeta **caltech** con las imágenes y los archivos *train.txt* y *test.txt* esté comprimida en un archivo **caltech.zip.** Hay que descomprimir los archivos cada vez que reseteamos el *runtime*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSkcQ-4d0JbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Directorio de trabajo\n",
        "DIR = \"/content/drive/My Drive/caltech/\" \n",
        "\n",
        "# Extraer archivos\n",
        "print(\"\\nEliminando datos anteriores...\")\n",
        "! rm -rf \"$DIR\"\n",
        "print(\"\\nExtrayendo datos...\")\n",
        "! unzip -q \"/content/drive/My Drive/caltech.zip\" -d \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvXTPzi20KPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#############################################################################\n",
        "# Visión por Computador. Curso 2019/20.\n",
        "# Práctica 2: Redes neuronales convolucionales. Parte 2: red ResNet50.\n",
        "# Antonio Coín Castro.\n",
        "#############################################################################\n",
        "\n",
        "#\n",
        "# LIBRERÍAS\n",
        "#\n",
        "\n",
        "# Generales\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Keras\n",
        "import keras\n",
        "import keras.utils as np_utils\n",
        "\n",
        "# Tensorflow\n",
        "from tensorflow.compat.v1 import logging\n",
        "\n",
        "# Modelos y capas\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Conv2D, Dense\n",
        "from keras.layers import Flatten, Dropout, BatchNormalization, Activation\n",
        "\n",
        "# Optimizador\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "\n",
        "# Función de pérdida\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "# ResNet\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "# Lectura y preprocesamiento de datos\n",
        "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "\n",
        "#\n",
        "# PARÁMETROS GLOBALES\n",
        "#\n",
        "\n",
        "N = 200                               # Número de clases\n",
        "EPOCHS_1 = 50                         # Épocas de entrenamiento para ejercicio 1\n",
        "EPOCHS_2 = 15                         # Épocas de entrenamiento para ejercicio 2\n",
        "BATCH_SIZE = 64                       # Tamaño de cada batch de imágenes\n",
        "SPLIT = 0.1                           # Partición para validación\n",
        "INPUT_SIZE = (224, 224)               # Dimensiones de las imágenes de entrada\n",
        "OUTPUT_SIZE = (2048,)                 # Dimensiones de las imágenes de salida\n",
        "INPUT_SHAPE = INPUT_SIZE + (3,)       # Formato de entrada de imágenes\n",
        "OUTPUT_SHAPE = (7, 7) + OUTPUT_SIZE   # Formato de salida de imágenes\n",
        "TAM = (10, 5)                         # Tamaño del plot\n",
        "ACC_NAME = \"acc\"                      # Nombre de la métrica de precisión\n",
        "\n",
        "#\n",
        "# FUNCIONES AUXILIARES\n",
        "#\n",
        "\n",
        "def wait():\n",
        "    \"\"\"Introduce una espera hasta que se pulse una tecla.\"\"\"\n",
        "\n",
        "    input(\"(Pulsa cualquier tecla para continuar...)\")\n",
        "\n",
        "#\n",
        "# LECTURA Y MODIFICACIÓN DEL CONJUNTO DE IMÁGENES\n",
        "#\n",
        "\n",
        "def read_im(names):\n",
        "    \"\"\"Lee las imágenes cuyos nombres están especificados en un vector de entrada.\n",
        "       Devuelve las imágenes en un vector y sus clases en otro.\n",
        "        - names: vector con los nombres (ruta relativa) de las imágenes.\"\"\"\n",
        "\n",
        "    classes = np.array([im.split('/')[0] for im in names])\n",
        "    vim = np.array([img_to_array(load_img(DIR + im, target_size = INPUT_SIZE)) \n",
        "                    for im in names])\n",
        "\n",
        "    return vim, classes\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Carga el conjunto de datos en 4 vectores: las imágenes de entrenamiento,\n",
        "       las clases de las imágenes de entrenamiento, las imágenes de test y las\n",
        "       clases de las imágenes de test.\n",
        "\n",
        "       Lee las imágenes y las clases de los ficheros 'train.txt' y 'test.txt'.\"\"\"\n",
        "\n",
        "    # Cargamos los ficheros\n",
        "    train_images = np.loadtxt(DIR + \"train.txt\", dtype = str)\n",
        "    test_images = np.loadtxt(DIR + \"test.txt\", dtype = str)\n",
        "\n",
        "    # Leemos las imágenes\n",
        "    train, train_classes = read_im(train_images)\n",
        "    test, test_classes = read_im(test_images)\n",
        "\n",
        "    # Convertimos las clases a números enteros\n",
        "    unique_classes = np.unique(np.copy(train_classes))\n",
        "    for i in range(len(unique_classes)):\n",
        "      train_classes[train_classes == unique_classes[i]] = i\n",
        "      test_classes[test_classes == unique_classes[i]] = i\n",
        "\n",
        "    # Convertimos los vectores de clases en matrices binarias\n",
        "    train_classes = np_utils.to_categorical(train_classes, N)\n",
        "    test_classes = np_utils.to_categorical(test_classes, N)\n",
        "\n",
        "    # Barajamos los datos\n",
        "    train_perm = np.random.permutation(len(train))\n",
        "    train = train[train_perm]\n",
        "    train_classes = train_classes[train_perm]\n",
        "\n",
        "    test_perm = np.random.permutation(len(test))\n",
        "    test = test[test_perm]\n",
        "    test_classes = test_classes[test_perm]\n",
        "\n",
        "    return train, train_classes, test, test_classes\n",
        "\n",
        "#\n",
        "# GRÁFICAS DE EVOLUCIÓN Y ESTADÍSTICAS\n",
        "#\n",
        "\n",
        "def show_evolution(hist, name):\n",
        "    \"\"\"Pinta dos gráficas: una con la evolución de la función de pérdida\n",
        "       en el conjunto de entrenamiento y en el de validación, y otra con la evolución\n",
        "       del accuracy en el conjunto de entrenamiento y en el de validación.\n",
        "        - hist: historial de entrenamiento del modelo.\n",
        "        - name: nombre del modelo.\"\"\"\n",
        "\n",
        "    # Evolución de las funciones de pérdida\n",
        "    loss = hist.history['loss']\n",
        "    val_loss = hist.history['val_loss']\n",
        "    plt.figure(figsize = TAM)\n",
        "    plt.plot(loss)\n",
        "    plt.plot(val_loss)\n",
        "    plt.legend([\"Training loss \" + name, \"Validation loss \" + name])\n",
        "    plt.show()\n",
        "\n",
        "    wait()\n",
        "\n",
        "    # Evolución del accuracy\n",
        "    acc = hist.history[ACC_NAME]\n",
        "    val_acc = hist.history[\"val_\" + ACC_NAME]\n",
        "    plt.figure(figsize = TAM)\n",
        "    plt.plot(acc)\n",
        "    plt.plot(val_acc)\n",
        "    plt.legend([\"Training accuracy \" + name, \"Validation accuracy \" + name])\n",
        "    plt.show()\n",
        "\n",
        "    wait()\n",
        "\n",
        "def show_stats(score, hist, name, show = True):\n",
        "    \"\"\"Muestra estadísticas de accuracy y loss y gráficas de evolución.\n",
        "        - score: métricas de evaluación.\n",
        "        - hist: historial de entrenamiento.\n",
        "        - name: nombre del modelo.\n",
        "        - show: controla si se muestran gráficas con estadísticas.\"\"\"\n",
        "\n",
        "    print(\"\\n---------- \" + name.upper() + \" EVALUATION ----------\")\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "    print()\n",
        "\n",
        "    # Mostramos gráficas\n",
        "    if show:\n",
        "        show_evolution(hist, name)\n",
        "\n",
        "#\n",
        "# CÁLCULO DE PRECISIÓN EN EL CONJUNTO DE TEST\n",
        "#\n",
        "\n",
        "def accuracy(labels, preds):\n",
        "    \"\"\"Deuelve la medida de precisión o 'accuracy' de un modelo sobre el conjunto\n",
        "       de entrenamiento: porcentaje de etiquetas predichas correctamente frente\n",
        "       al total.\n",
        "        - labels: etiquetas correctas en formato matriz binaria.\n",
        "        - preds: etiquetas predichas en formato matriz binaria.\"\"\"\n",
        "\n",
        "    # Convertimos matrices a vectores\n",
        "    labels = np.argmax(labels, axis = 1)\n",
        "    preds = np.argmax(preds, axis = 1)\n",
        "\n",
        "    return sum(labels == preds) / len(labels)\n",
        "\n",
        "#\n",
        "# COMPILACIÓN DEL MODELO\n",
        "#\n",
        "\n",
        "def compile(model, lr = 0.01, use_sgd = True):\n",
        "    \"\"\"Definición del optimizador y compilación del modelo.\n",
        "        - model: modelo a compilar.\n",
        "        - lr: learning rate.\n",
        "        - use_sgd: decide si se optimiza con 'sgd' (True) o con\n",
        "          'rmsprop' (False).\"\"\"\n",
        "\n",
        "    # Definimos el optimizador\n",
        "    if use_sgd:\n",
        "      opt = SGD(lr = lr, decay = 1e-6,\n",
        "                momentum = 0.9, nesterov = True)\n",
        "    else:\n",
        "      opt = RMSprop(lr = lr)\n",
        "\n",
        "    # Compilamos el modelo\n",
        "    model.compile(loss = categorical_crossentropy,\n",
        "                  optimizer = opt,\n",
        "                  metrics = [ACC_NAME])\n",
        "\n",
        "#\n",
        "# ENTRENAMIENTO DEL MODELO\n",
        "#\n",
        "\n",
        "def train(model, epochs, x_train, y_train):\n",
        "    \"\"\"Entrenar el modelo con los datos de entrenamiento. Devuelve\n",
        "       el historial de entrenamiento.\n",
        "        - model: modelo a entrenar.\n",
        "        - epochs: épocas de entrenamiento.\n",
        "        - x_train, y_train: datos de entrenamiento.\"\"\"\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    hist = model.fit(x_train, y_train,\n",
        "                     batch_size = BATCH_SIZE,\n",
        "                     epochs = epochs,\n",
        "                     verbose = 1,\n",
        "                     validation_split = SPLIT)\n",
        "\n",
        "    return hist\n",
        "\n",
        "def train_gen(model, datagen, epochs, x_train, y_train):\n",
        "    \"\"\"Entrenar el modelo con los datos de entrenamiento a partir de\n",
        "       un generador de imágenes. Devuelve el historial de entrenamiento.\n",
        "        - model: modelo a entrenar.\n",
        "        - epochs: épocas de entrenamiento.\n",
        "        - x_train, y_train: datos de entrenamiento.\"\"\"\n",
        "\n",
        "    hist = model.fit_generator(datagen.flow(x_train,\n",
        "                                            y_train,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            subset = 'training'),\n",
        "                               epochs = epochs,\n",
        "                               steps_per_epoch = len(x_train) * (1 - SPLIT) / BATCH_SIZE,\n",
        "                               verbose = 1,\n",
        "                               validation_data = datagen.flow(x_train,\n",
        "                                                              y_train,\n",
        "                                                              batch_size = BATCH_SIZE,\n",
        "                                                              subset = 'validation'),\n",
        "                               validation_steps = len(x_train) * SPLIT / BATCH_SIZE)\n",
        "    \n",
        "    return hist\n",
        "    \n",
        "#\n",
        "# PREDICIÓN Y EVALUACIÓN\n",
        "#\n",
        "\n",
        "def predict_gen(model, datagen, x):\n",
        "    \"\"\"Predicción de etiquetas sobre un conjunto de imágenes.\n",
        "        - model: modelo a usar para predecir.\n",
        "        - datagen: generador de imágenes.\n",
        "        - x: conjunto de datos para predecir su clase.\"\"\"\n",
        "\n",
        "    preds = model.predict_generator(datagen.flow(x,\n",
        "                                                 batch_size = 1,\n",
        "                                                 shuffle = False),\n",
        "                                    verbose = 1,\n",
        "                                    steps = len(x))\n",
        "\n",
        "    return preds\n",
        "\n",
        "def evaluate(model, x_test, y_test):\n",
        "    \"\"\"Evaluar el modelo sobre el conjunto de test.\n",
        "        - model: modelo a usar para evaluar.\n",
        "        - x_test, y_test: datos de test.\"\"\"\n",
        "\n",
        "    score = model.evaluate(x_test, y_test, verbose = 0)\n",
        "\n",
        "    return score\n",
        "\n",
        "def evaluate_gen(model, datagen, x_test, y_test):\n",
        "    \"\"\"Evaluar el modelo sobre el conjunto de test, usando un generador\n",
        "       de imágenes.\n",
        "        - model: modelo a usar para evaluar.\n",
        "        - datagen: generador de imágenes.\n",
        "        - x_test, y_test: datos de test.\"\"\"\n",
        "\n",
        "    score = model.evaluate_generator(datagen.flow(x_test, \n",
        "                                                  y_test,\n",
        "                                                  batch_size = 1,\n",
        "                                                  shuffle = False), \n",
        "                                      verbose = 0,\n",
        "                                      steps = len(x_test))\n",
        "    \n",
        "    return score\n",
        "\n",
        "#\n",
        "# EJECUCIÓN COMPLETA DEL MODELO\n",
        "#\n",
        "\n",
        "def execute(model_gen, epochs, x_train, y_train, x_test, y_test):\n",
        "    \"\"\"Compilar, entrenar y evaluar un modelo. Devuelve el\n",
        "       historial de entrenamiento y la evaluación del modelo.\n",
        "        - model_gen: función que devuelve el modelo en cuestión.\n",
        "        - epochs: épocas de entrenamiento.\n",
        "        - x_train, y_train: datos de entrenamiento.\n",
        "        - x_test, y_test: datos de test.\"\"\"\n",
        "\n",
        "    # Construimos el modelo\n",
        "    model = model_gen()\n",
        "\n",
        "    # Compilamos el modelo\n",
        "    compile(model)\n",
        "\n",
        "    # Mostramos el modelo\n",
        "    print(model.summary())\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    hist = train(model, epochs, x_train, y_train)\n",
        "\n",
        "    # Evaluamos el modelo\n",
        "    score = evaluate(model, x_test, y_test)\n",
        "\n",
        "    return score, hist\n",
        "\n",
        "#\n",
        "# EJERCICIO 1: RED PREENTRENADA COMO EXTRACTOR DE CARACTERÍSTICAS\n",
        "#\n",
        "\n",
        "def fc_model():\n",
        "    \"\"\"Devuelve un modelo fully-connected básico.\"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(1024,\n",
        "                    activation = 'relu',\n",
        "                    input_shape = OUTPUT_SIZE))\n",
        "    model.add(Dense(512, activation = 'relu'))\n",
        "    model.add(Dropout(0.7))\n",
        "\n",
        "    model.add(Dense(N, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def conv_model():\n",
        "    \"\"\"Devuelve un modelo convolucional básico.\"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64,\n",
        "                     kernel_size = (3, 3),\n",
        "                     use_bias = False,\n",
        "                     activation = 'relu',\n",
        "                     input_shape = OUTPUT_SHAPE))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, \n",
        "                    activation = 'relu', \n",
        "                    use_bias = False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.7))\n",
        "\n",
        "    model.add(Dense(N,\n",
        "                    activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def resnet_feature_extraction(use_conv = False, show = True):\n",
        "    \"\"\"Usar ResNet50 preentrenada en ImageNet como un extractor de características,\n",
        "       para confeccionar un modelo que clasfique imágenes del conjunto Caltech-UCSD.\n",
        "        - use_conv: tipo de modelo usado para \"rellenar\" la red. Puede ser True\n",
        "          para añadir capas convolucionales o False para añadir directamente capas\n",
        "          fully-connected.\n",
        "        - show: controla si se muestran gráficas con estadísticas.\"\"\"\n",
        "\n",
        "    # Cargamos los datos\n",
        "    print(\"Leyendo imágenes...\\n\")\n",
        "    x_train, y_train, x_test, y_test = load_data()\n",
        "\n",
        "    # Creamos un generador para entrenamiento y otro para test\n",
        "    datagen_train = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "    datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "\n",
        "    # Decidimos el formato de salida de la red ResNet50\n",
        "    if use_conv:\n",
        "        pooling_type = None   # Salida: tensor 7 x 8 x 2048\n",
        "        model_gen = conv_model\n",
        "    else:\n",
        "        pooling_type = 'avg'  # Salida: vector de 2048 entradas\n",
        "        model_gen = fc_model\n",
        "\n",
        "    # Usamos ResNet50 preentrenada en ImageNet sin la última capa\n",
        "    resnet = ResNet50(weights = 'imagenet',\n",
        "                     include_top = False,\n",
        "                     pooling = pooling_type,\n",
        "                     input_shape = INPUT_SHAPE)\n",
        "\n",
        "    # Extraemos características de las imágenes con el modelo anterior\n",
        "    print(\"Extrayendo características...\\n\")\n",
        "    features_train = predict_gen(resnet, datagen_train, x_train)\n",
        "    features_test = predict_gen(resnet, datagen_test, x_test)\n",
        "\n",
        "    # Ejecutamos un modelo con las características extraídas como entrada\n",
        "    score, hist = execute(model_gen, EPOCHS_1,\n",
        "                          features_train, y_train, features_test, y_test)\n",
        "\n",
        "    # Mostramos estadísticas\n",
        "    if show:\n",
        "        show_stats(score, hist, model_gen.__name__, show = show)\n",
        "\n",
        "#\n",
        "# EJERCICIO 2: FINE-TUNING EN RED PREENTRENADA \n",
        "#\n",
        "\n",
        "def fc_model_2(x):\n",
        "    \"\"\"Devuelve un modelo fully-connected básico (instancia de Model).\n",
        "        - x: capa sobre la que construir el modelo.\"\"\"\n",
        "\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(N, activation='softmax')(x)\n",
        "\n",
        "    return output\n",
        "\n",
        "def resnet_fine_tuning(show = True, save_w = False, load_w = False):\n",
        "    \"\"\"Usar ResNet50 preentrenada en ImageNet para hacer fine tuning y\n",
        "       confeccionar un modelo que clasfique imágenes del conjunto Caltech-UCSD.\n",
        "        - save_w: controla si se guardan los pesos aprendidos en un fichero.\n",
        "        - load_w: controla si se cargan pesos precalculados desde un fichero.\n",
        "        - show: controla si se muestran gráficas con estadísticas.\"\"\"\n",
        "\n",
        "    # Nombre de fichero para guardar/cargar pesos\n",
        "    file_w = \"/content/drive/My Drive/resnet_weights.h5\"\n",
        "\n",
        "    # Cargamos los datos\n",
        "    print(\"Leyendo imágenes...\\n\")\n",
        "    x_train, y_train, x_test, y_test = load_data()\n",
        "\n",
        "    # Creamos un generador para entrenamiento y otro para test\n",
        "    datagen_train = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
        "                                       validation_split = SPLIT)\n",
        "    datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "\n",
        "    # Usamos ResNet50 preentrenada en ImageNet sin la última capa\n",
        "    resnet = ResNet50(weights = 'imagenet',\n",
        "                      include_top = False,\n",
        "                      pooling = 'avg',\n",
        "                      input_shape = INPUT_SHAPE)\n",
        "\n",
        "    # Definimos un nuevo modelo a partir de ResNet50\n",
        "    output = fc_model_2(resnet.output)\n",
        "    model = Model(inputs=resnet.input, outputs=output)\n",
        "    \n",
        "    # Mostramos el modelo\n",
        "    print(model.summary())\n",
        "\n",
        "    # Compilamos el modelo\n",
        "    compile(model)\n",
        "\n",
        "    # Cargamos pesos precalculados\n",
        "    if load_w:\n",
        "      print(\"\\nCargando pesos precalculados de \" + file_w)\n",
        "      model.load_weights(file_w)\n",
        "\n",
        "    # Entrenamos el modelo\n",
        "    hist = train_gen(model, datagen_train, EPOCHS_2, x_train, y_train)\n",
        "    \n",
        "    # Guardamos los pesos aprendidos\n",
        "    if save_w:\n",
        "      print(\"\\nGuardando pesos aprendidos en \" + file_w)\n",
        "      model.save_weights(file_w)\n",
        "\n",
        "    # Evaluamos el modelo\n",
        "    print(\"\\nEvaluando modelo...\")\n",
        "    score = evaluate_gen(model, datagen_test, x_test, y_test)\n",
        "\n",
        "    # Mostramos estadísticas\n",
        "    if show:\n",
        "      show_stats(score, hist, \"fine_tuning\", show = True)\n",
        "\n",
        "#\n",
        "# FUNCIÓN PRINCIPAL\n",
        "#\n",
        "\n",
        "def main():\n",
        "    \"\"\"Ejecuta la segunda parte de la práctica 2 paso a paso.\"\"\"\n",
        "\n",
        "    # No mostrar warnings de TensorFlow\n",
        "    logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "    print(\"\\n--- EJERCICIO 1: EXTRACTOR DE CARACTERÍSTICAS ---\\n\")\n",
        "    resnet_feature_extraction()\n",
        "\n",
        "    print(\"\\n--- EJERCICIO 2: FINE-TUNING ---\\n\")\n",
        "    resnet_fine_tuning()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXFvNoVu0LJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ejecutar la segunda parte de la práctica\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}